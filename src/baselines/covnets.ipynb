{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DINOv2 Model (HuggingFace)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "dino_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "\n",
    "# Load VGG16 Model (Keras)\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, model_type='vgg16'):\n",
    "    try:\n",
    "        if model_type == 'vgg16':\n",
    "            # VGG16 Feature Extraction\n",
    "            image = load_img(image_path, target_size=(224, 224))\n",
    "            image_array = img_to_array(image)\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            image_array = preprocess_input(image_array)\n",
    "            features = vgg16.predict(image_array)\n",
    "            return features.flatten()\n",
    "        elif model_type == 'dinov2':\n",
    "            # DINOv2 Feature Extraction\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "                outputs = dino_model(**inputs)\n",
    "                image_features = outputs.last_hidden_state\n",
    "                # Mean pooling of the embeddings\n",
    "                return image_features.mean(dim=1).squeeze().cpu().numpy()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'vgg16' or 'dinov2'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features for {image_path} using {model_type}: {e}\")\n",
    "        return None  \n",
    "\n",
    "# Helper function to compute similarity score (0-4 scale)\n",
    "def similarity_score(vector1, vector2):\n",
    "    try:\n",
    "        cosine_sim = cosine_similarity([vector1], [vector2])[0][0]\n",
    "        if cosine_sim > 0.85:\n",
    "            return 4\n",
    "        elif cosine_sim > 0.75:\n",
    "            return 3\n",
    "        elif cosine_sim > 0.65:\n",
    "            return 2\n",
    "        elif cosine_sim > 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating similarity score: {e}\")\n",
    "        return 0  # Assign 0 similarity in case of an error\n",
    "\n",
    "# Function to extract article and image numbers for sorting\n",
    "def extract_article_image_nums(filename):\n",
    "    match = re.match(r\"image_(\\d+)_(\\d+)\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    return float('inf'), float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_semantic_similarity(input_dir, website_list=None, model_type='vgg16'):\n",
    "    if website_list is None:\n",
    "        website_list = [f for f in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, f))]\n",
    "    \n",
    "    for website in tqdm(website_list, desc=\"Processing Websites\"):\n",
    "        website_path = os.path.join(input_dir, website)\n",
    "        if not os.path.isdir(website_path):\n",
    "            print(f\"Skipping {website}: Not a directory.\")\n",
    "            continue\n",
    "        \n",
    "        for category in tqdm(os.listdir(website_path), desc=f\"Processing Categories in {website}\", leave=False):\n",
    "            category_path = os.path.join(website_path, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            \n",
    "            image_files = sorted(\n",
    "                [f for f in os.listdir(category_path) if f.endswith(('.jpg', '.png', '.jpeg'))],\n",
    "                key=extract_article_image_nums\n",
    "            )\n",
    "            image_paths = [os.path.join(category_path, img) for img in image_files]\n",
    "            \n",
    "            features = {}\n",
    "            for img, path in zip(image_files, image_paths):\n",
    "                features[img] = extract_features(path, model_type=model_type)\n",
    "            \n",
    "            n = len(image_files)\n",
    "            similarity_matrix = np.zeros((n, n))\n",
    "            \n",
    "            for i in range(n):\n",
    "                for j in range(i, n):\n",
    "                    if i == j:\n",
    "                        similarity_matrix[i, j] = 4  # Diagonal elements\n",
    "                    else:\n",
    "                        try:\n",
    "                            vec1 = features[image_files[i]]\n",
    "                            vec2 = features[image_files[j]]\n",
    "                            if vec1 is None or vec2 is None:\n",
    "                                similarity_matrix[i, j] = 0\n",
    "                            else:\n",
    "                                similarity_matrix[i, j] = similarity_score(vec1, vec2)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing pair ({image_files[i]}, {image_files[j]}): {e}\")\n",
    "                            similarity_matrix[i, j] = 0\n",
    "            \n",
    "            # Mirror upper triangle to lower triangle\n",
    "            similarity_matrix += np.triu(similarity_matrix, k=1).T\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_path = os.path.join(category_path, f\"{model_type}_pred_labels.csv\")\n",
    "            image_names = [img.replace('.jpg', '').replace('.png', '').replace('.jpeg', '') for img in image_files]\n",
    "            df = pd.DataFrame(similarity_matrix.astype(int), index=image_names, columns=image_names)\n",
    "            df.to_csv(output_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"../../data\"\n",
    "compute_semantic_similarity(input_directory, model_type='dinov2')  # Use 'vgg16' or 'dinov2'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
