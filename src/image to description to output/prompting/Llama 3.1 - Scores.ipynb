{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Imports**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1606,"status":"ok","timestamp":1728592621200,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"gv_RFPMZARqP"},"outputs":[],"source":["import requests\n","from json import loads, dumps\n","from time import time, sleep\n","from tqdm import tqdm\n","import os\n","import re\n","import pandas as pd\n","import numpy as np\n","import shutil\n","from jinja2 import Template\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","import concurrent.futures"]},{"cell_type":"markdown","metadata":{},"source":["Loading websites from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_dir = '../../../data'\n","os.chdir(base_dir)\n","websites = os.listdir('.')"]},{"cell_type":"markdown","metadata":{},"source":["## Prompts"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1728592646371,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"5lItNJg3AatE"},"outputs":[],"source":["base_prompt = \"\"\"\n","You are tasked with evaluating the replaceability of two images from different articles within the same category of a news website.\n","Consider how well the two images align with each other in terms of their content and context.\n","\n","Use the following rating scale:\n","\n","0: Not replaceable\n","1: Somewhat replaceable\n","2: Moderately replaceable\n","3: Very replaceable\n","4: Completely replaceable\n","\n","Image Descriptions and Associated Context:\n","<image_a_description>\n","    {{ image_a_description }}\n","</image_a_description>\n","<image_a_context>\n","    {{ image_a_context }}\n","</image_a_context>\n","\n","<image_b_description>\n","    {{ image_b_description }}\n","</image_b_description>\n","<image_b_context>\n","    {{ image_b_context }}\n","</image_b_context>\n","\"\"\"\n","\n","prompt1 = \"\"\"You are tasked with evaluating the semantic replaceability of two images (Image A and Image B) from different articles within the same category of a news website.\n","Your goal is to determine how interchangeable these images are based on their contexts and semantic similarity of the images, which include the article headings and alt text (where available).\n","\n","Use the following rating scale for replaceability:\n","0: Not replaceable\n","1: Somewhat replaceable\n","2: Moderately replaceable\n","3: Very replaceable\n","4: Completely replaceable\n","\n","Here are the contexts for the two images:\n","\n","<image_a_description>\n","    {{ image_a_description }}\n","</image_a_description>\n","<image_a_context>\n","    {{ image_a_context }}\n","</image_a_context>\n","\n","<image_b_description>\n","    {{ image_b_description }}\n","</image_b_description>\n","<image_b_context>\n","    {{ image_b_context }}\n","</image_b_context>\n","\n","Consider the following factors when evaluating their semantic replaceability:\n","1. Similarity of topics\n","2. Specificity of information conveyed (e.g, specific people, places etc)\n","3. Emotional tone or impact\n","4. Potential for misinterpretation if swapped\n","\"\"\"\n","\n","#########################################################################################\n","\n","cot = \"\"\"\n","Using chain of thought prompting, analyze these two images and rate their replaceability. \n","Break down your thought process step by step. \n","Write your answer in the following format:\n","\n","<rating>\n","[Your rating (0-4)]\n","</rating>\n","<justification>\n","Explanation: [Brief explanation for your rating, synthesizing your analysis of all factors]\n","</justification>\n","\"\"\"\n","\n","format = \"\"\"\n","Write your answer in the following format:\n","\n","<rating>\n","[Your rating (0-4)]\n","</rating>\n","\"\"\""]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":579,"status":"ok","timestamp":1728593454655,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"o_jQmaFDBK_0"},"outputs":[],"source":["def send_prompt(prompt):\n","    data = {\n","    \"input\": {\n","        \"top_p\": 0.9,\n","        \"prompt\": prompt,\n","        \"max_tokens\": 1024*4,\n","        \"min_tokens\": 0,\n","        \"temperature\": 0.8,\n","        \"system_prompt\": f\"You are a helpful visual assistant, and the descriptions will solely be used for research purposes. There's no intention to harm or hurt any specific group of people.\",\n","        \"presence_penalty\": 0,\n","        \"frequency_penalty\": 0\n","        }\n","    }\n","\n","    while True:\n","        try:\n","            resp_post = requests.post('https://replicate.com/api/models/meta/meta-llama-3.1-405b-instruct/predictions', json=data)\n","            token_id = resp_post.json()['id']\n","            break\n","        except:\n","            continue\n","\n","    return token_id\n","\n","def read_response(token_id):\n","    resp_get = requests.get(f'https://replicate.com/api/predictions/{token_id}')\n","\n","    start = time()\n","\n","    try:\n","\n","        while resp_get.json()['status'] != 'succeeded' and time() - start < 25:\n","            resp_get = requests.get(f'https://replicate.com/api/predictions/{token_id}')\n","\n","        if resp_get.json()['completed_at'] == None :\n","            output = 'Timeout'\n","        else:\n","            output = ''.join(resp_get.json()['output'])\n","    except:\n","        output = 'Timeout'\n","\n","    return output"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1728592646372,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"G4M4DKppAt7W"},"outputs":[],"source":["def extract_info(row):\n","    return row['description'], row['article_heading'], row['alt']"]},{"cell_type":"markdown","metadata":{},"source":["Prompt Generation"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":20871,"status":"ok","timestamp":1728602446987,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"-TMyz2dAAncy"},"outputs":[],"source":["def prepare_model_prompts(websites, prompt, label):\n","    columns = ['headline 1', 'alt 1', 'image 1', 'image 2', 'headline 2', 'alt 2', 'prompt', 'response']\n","\n","    for website in websites:\n","        dir_path = f'../src/description to output/descriptions/temp/{website}/{label}'\n","        \n","        if not os.path.exists(dir_path):\n","            os.makedirs(dir_path)\n","\n","        for category in os.listdir(website):\n","            df = pd.read_csv(f'{website}/{category}/image_descriptions.csv', index_col=0)\n","\n","            images = df.index.tolist()\n","            row = []\n","\n","            for i in range(len(images)):\n","                for j in range(i+1, len(images)):\n","                    article_1 = int(re.search(r'\\d+(?=_|$)', images[i]).group())\n","                    article_2 = int(re.search(r'\\d+(?=_|$)', images[j]).group())\n","                    if article_1 != article_2:\n","                        description_1, headline_1, alt_1 = extract_info(df.iloc[i])\n","                        description_2, headline_2, alt_2 = extract_info(df.iloc[j])\n","                        data = {\n","                            \"image_a_description\": f\"Description: {description_1}\",\n","                            \"image_a_context\": f\"Alt Text: {alt_1}, Heading: {headline_1}\",\n","                            \"image_b_description\": f\"Description: {description_2}\",\n","                            \"image_b_context\": f\"Alt Text: {alt_2}, Heading: {headline_2}\"\n","                        }\n","                        template = Template(prompt + cot)\n","                        rendered_text = template.render(data)\n","\n","                        row.append([headline_1, alt_1, images[i], images[j], headline_2, alt_2, rendered_text, ''])\n","\n","            pd.DataFrame(row, columns=columns).to_csv(f'{dir_path}/{category}', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Parallelizing Llama Responses with concurrent threads"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1728602458979,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"jqMiKpTpIMfn"},"outputs":[],"source":["def process_prompts(prompts, website='', category=''):\n","    outputs = [None] * len(prompts)  # Initialize a list to hold outputs in original order\n","\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n","        # Send all prompts in parallel\n","        futures = {executor.submit(send_prompt, prompt): idx for idx, prompt in enumerate(prompts)}\n","\n","        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=f\"Sending Prompts website: {website} category: {category}\"):\n","            idx = futures[future]  # Get the original index\n","            token_id = future.result()\n","            if token_id is not None:\n","                outputs[idx] = token_id  # Store token_id at the original index\n","\n","    return outputs  # Return only the token IDs\n","\n","\n","def read_all_responses(outputs, website='', category=''):\n","    response_outputs = [None] * len(outputs)  # Initialize to hold responses in the original order\n","\n","    # Filter only valid token IDs\n","    valid_token_ids = [token_id for token_id in outputs if token_id is not None]\n","\n","    if valid_token_ids:  # Only proceed if we have valid token IDs\n","        with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:\n","            response_futures = {executor.submit(read_response, token_id): idx for idx, token_id in enumerate(outputs) if token_id is not None}\n","\n","            for future in tqdm(concurrent.futures.as_completed(response_futures), total=len(response_futures), desc=f\"Reading Responses website: {website} category: {category}\"):\n","                idx = response_futures[future]  # Get the original index\n","                response = future.result()\n","                response_outputs[idx] = response  # Store the response at the original index\n","\n","    return response_outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_dir_path(website, label):\n","    return f'../src/description to output/descriptions/temp/{website}/{label}'\n","\n","def run_llama(websites, label):\n","    # Initialize a dictionary to hold token IDs for each category    \n","    all_token_ids = {}\n","\n","    # Step 1: Iterate over all websites and categories to collect token IDs\n","    for website in websites:\n","        all_token_ids[website] = {}  # Initialize a dict for each website\n","        dir_path = get_dir_path(website, label)\n","\n","        for category in os.listdir(dir_path):\n","            df = pd.read_csv(f'{dir_path}/{category}')\n","            prompts = df['prompt'].tolist()\n","\n","            # Get token IDs for all prompts in this category\n","            token_ids = process_prompts(prompts, website, category.replace('.csv', ''))\n","\n","            # Store the token IDs for this category\n","            all_token_ids[website][category] = token_ids\n","        print()\n","\n","    # Step 2: Now read responses for all collected token IDs\n","    for website, categories in all_token_ids.items():\n","        dir_path = get_dir_path(website, label)\n","\n","        for category, token_ids in categories.items():\n","            # Read responses for the collected token IDs\n","            responses = read_all_responses(token_ids, website, category.replace('.csv', ''))\n","\n","            # Update DataFrame with responses and save\n","            df = pd.read_csv(f'{dir_path}/{category}')\n","            df['response'] = responses\n","            pattern = r'<rating>\\s*[\\[\\s]*(\\d+)[\\]\\s]*</rating>'\n","            scores = []\n","            for resp in responses:\n","                match = re.search(pattern, resp)\n","                if match:\n","                    scores.append(int(match.group(1)))\n","                else:\n","                    scores.append(9)  # Add 9 if no match\n","\n","            df['score'] = scores\n","            df.to_csv(f'{dir_path}/{category}', index=False)\n","        print()\n"]},{"cell_type":"markdown","metadata":{},"source":["Verification if all the responses were fetched"]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":1302,"status":"ok","timestamp":1728604408138,"user":{"displayName":"Ayain Fida","userId":"11493001773162111830"},"user_tz":-300},"id":"u28jekaVLEqU"},"outputs":[],"source":["def resolve_descripancies(websites, label, runs=3):\n","    while (runs > 0):\n","        re_run = []\n","\n","        for website in websites:\n","            dir_path = get_dir_path(website, label)\n","            for category in os.listdir(dir_path):\n","                df = pd.read_csv(f'{dir_path}/{category}')\n","                timeout = df[df['score'] == 9]\n","                if timeout.shape[0] > 0:\n","                    re_run.append([f'{dir_path}/{category}', timeout.index.tolist(), [send_prompt(prompt) for prompt in timeout['prompt'].tolist()]])\n","\n","        for file, index_list, token_ids in re_run:\n","            df = pd.read_csv(file)\n","\n","            for i in range(len(index_list)):\n","                index = index_list[i]\n","                token_id = token_ids[i]\n","                response = read_response(token_id)\n","                df.loc[index, 'response'] = response\n","                pattern = r'<rating>\\s*[\\[\\s]*(\\d+)[\\]\\s]*</rating>'\n","\n","                match = re.search(pattern, response)\n","                if match:\n","                    score = int(match.group(1))\n","                else:\n","                    score = 9  # Add 9 if no match\n","                \n","                df.loc[index, 'score'] = score\n","            \n","            df.to_csv(file, index=False)\n","        \n","        runs -= 1\n"]},{"cell_type":"markdown","metadata":{},"source":["### Creating similarity matrices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sort_key(image_name):\n","    match = re.match(r'image_(\\d+)_(\\d+)', image_name)\n","    if match:\n","        x = int(match.group(1))  # Extract the first number (x)\n","        y = int(match.group(2))  # Extract the second number (y)\n","        return (x, y)  # Return a tuple for sorting\n","\n","def compute_similarity_matrices(websites, label):\n","    for website in websites:\n","        dir_path = get_dir_path(website, label)\n","        try:\n","            for category in tqdm(os.listdir(website), desc=f'Processing {website}'):\n","                df = pd.read_csv(f'{dir_path}/{website}/{category}.csv')\n","                score_list = df['score'].tolist()\n","                count = 0\n","                x = list(set(df['image 1'].tolist()) | set(df['image 2'].tolist()))\n","                image_num = sorted([sort_key(img) for img in x])\n","                image_list = [f'image_{image_num[i][0]}_{image_num[i][1]}' for i in range(len(image_num))]\n","                n = len(image_list)\n","                scores = [[4 if i == j else 0 for j in range(n)] for i in range(n)]\n","                matrix = pd.DataFrame(scores, columns=image_list, index=image_list)\n","                for i in range(n):\n","                    for j in range(i+1,n):\n","                        img1 = sort_key(image_list[i])\n","                        img2 = sort_key(image_list[j])\n","                        if img1[0] != img2[0]:\n","                            matrix.at[image_list[i], image_list[j]] = score_list[count]\n","                            matrix.at[image_list[j], image_list[i]] = matrix.at[image_list[i], image_list[j]]\n","                            count += 1\n","                matrix.to_csv(f'{website}/{category}/llama_pred_labels{\"_0\" if label == 'base' else (\"_fewshot\" if label == 'few-shot' else \"\")}.csv')\n","        except:\n","            continue"]},{"cell_type":"markdown","metadata":{},"source":["Base Prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["websites = [] # Add sample\n","\n","prepare_model_prompts(websites=websites, prompt=base_prompt, label='base')\n","run_llama(websites=websites, label='base')\n","resolve_descripancies(websites=websites, labels='base') # can also adjust runs if network issues\n","compute_similarity_matrices(websites=websites, label='base')"]},{"cell_type":"markdown","metadata":{},"source":["Prompt 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["websites = [] # Add sample\n","\n","prepare_model_prompts(websites=websites, prompt=base_prompt, label='prompt 1')\n","run_llama(websites=websites, label='prompt 1')\n","resolve_descripancies(websites=websites, labels='prompt 1')\n","compute_similarity_matrices(websites=websites, label='prompt-1')"]},{"cell_type":"markdown","metadata":{},"source":["## Few-shot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","def generate_embeddings(x):\n","    return model.encode(x)\n","\n","def find_most_similar(new_value, stored_values, stored_embeddings):\n","    new_embedding = model.encode([new_value])\n","    similarities = cosine_similarity(new_embedding, stored_embeddings)\n","    most_similar_idx = np.argmax(similarities)\n","    return most_similar_idx, similarities[0][most_similar_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt2 = \"\"\"You are tasked with evaluating the semantic replaceability of two images (Image A and Image B) from different articles within the same category of a news website.\n","Your goal is to determine how interchangeable these images are based on their contexts and semantic similarity of the images, which include the article headings and alt text (where available).\n","\n","Use the following rating scale for replaceability:\n","0: Not replaceable\n","1: Somewhat replaceable\n","2: Moderately replaceable\n","3: Very replaceable\n","4: Completely replaceable\n","\n","Here are the contexts for the two images:\n","\n","<image_a_description>\n","    {{ image_a_description }}\n","</image_a_description>\n","<image_a_context>\n","    {{ image_a_context }}\n","</image_a_context>\n","\n","<image_b_description>\n","    {{ image_b_description }}\n","</image_b_description>\n","<image_b_context>\n","    {{ image_b_context }}\n","</image_b_context>\n","\n","Consider the following factors when evaluating their semantic replaceability:\n","1. Similarity of topics\n","2. Specificity of information conveyed (e.g, specific people, places etc)\n","3. Emotional tone or impact\n","4. Potential for misinterpretation if swapped\n","\"\"\"\n","\n","cot = \"\"\"\n","Now, based on the examples provided above, and using chain of thought prompting, analyze these two images and rate their similarity.\n","Break down your thought process step by step.\n","Write your answer in the following format:\n","\n","<rating>\n","[Your rating (0-4)]\n","</rating>\n","<justification>\n","Explanation: [Brief explanation for your rating, synthesizing your analysis of all factors]\n","</justification>\n","\"\"\"\n","\n","few_shot_example = \"\"\"\n","<example_number>\n","    {{ example_number }}\n","</example_number>\n","\n","<image_a_description>\n","    {{ image_a_description }}\n","</image_a_description>\n","<image_a_context>\n","    {{ image_a_context }}\n","</image_a_context>\n","\n","<image_b_description>\n","    {{ image_b_description }}\n","</image_b_description>\n","<image_b_context>\n","    {{ image_b_context }}\n","</image_b_context>\n","\n","<rating>\n","    {{ rating }}\n","</rating>\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_few_shot_examples(category, image, descriptions):\n","    df = pd.read_csv(f'../src/description to output/prompting/train/{category}')\n","    article = int(re.search(r'\\d+(?=_|$)', image).group())\n","    indices = list(set(df[df['image 1'] == image].index.tolist()) | set(df[df['image 2'] == image].index.tolist()))\n","    prompts = []\n","    for i, idx in enumerate(indices):\n","        a_1 = int(re.search(r'\\d+(?=_|$)', df.loc[idx, 'image 1']).group())\n","        a_2 = int(re.search(r'\\d+(?=_|$)', df.loc[idx, 'image 2']).group())\n","        data = {\n","            \"example_number\": f\"Example {i+1}\",\n","            \"image_a_description\": f\"Description: {descriptions[a_1-1]}\",\n","            \"image_a_context\": f\"Alt Text: {df.loc[idx, 'alt 1']}, Heading: {df.loc[idx, 'headline 1']}\",\n","            \"image_b_description\": f\"Description: {descriptions[a_2-1]}\",\n","            \"image_b_context\": f\"Alt Text: {df.loc[idx, 'alt 2']}, Heading: {df.loc[idx, 'headline 2']}\",\n","            \"rating\": f\"{df.loc[idx, 'label']}\"\n","        }\n","        template = Template(few_shot_example)\n","        rendered_text = template.render(data)\n","        prompts.append(rendered_text)\n","\n","    output = \"\"\n","    for prompt in prompts:\n","        output += prompt + \"\\n\"\n","\n","    return output"]},{"cell_type":"markdown","metadata":{},"source":["Prompt Generation for Dynamic Few-shot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_few_shot_prompts(websites, prompt, label='few-shot'):\n","    train_dir = '../src/description to output/prompting/train'\n","\n","    few_shot_categories = os.listdir(train_dir)\n","    few_shot_embeddings = generate_embeddings(few_shot_categories)\n","    \n","    columns = ['headline 1', 'alt 1', 'image 1', 'image 2', 'headline 2', 'alt 2', 'prompt', 'response']\n","\n","    for website in websites:\n","        dir_path = f'../src/description to output/descriptions/temp/{website}/{label}'\n","\n","        if not os.path.exists(dir_path):\n","            os.makedirs(dir_path)\n","\n","        for category in os.listdir(website):\n","            df = pd.read_csv(f'{website}/{category}/image_descriptions.csv', index_col=0)\n","\n","            index, _ = find_most_similar(category.replace(\".csv\", \"\"), few_shot_categories, few_shot_embeddings)\n","            select_category = few_shot_categories[index]\n","            images = df.index.tolist()\n","            few_shot_df = pd.read_csv(f'{train_dir}/{select_category}/descriptions.csv')\n","            desc = few_shot_df['description'].tolist()\n","            desc_embeddings = generate_embeddings(desc)\n","\n","            row = []\n","\n","            for i in range(len(images)):\n","                for j in range(i+1, len(images)):\n","                    article_1 = int(re.search(r'\\d+(?=_|$)', images[i]).group())\n","                    article_2 = int(re.search(r'\\d+(?=_|$)', images[j]).group())\n","                    if article_1 != article_2:\n","                        description_1, headline_1, alt_1 = extract_info(df.iloc[i])\n","                        description_2, headline_2, alt_2 = extract_info(df.iloc[j])\n","                        data = {\n","                            \"image_a_description\": f\"Description: {description_1}\",\n","                            \"image_a_context\": f\"Alt Text: {alt_1}, Heading: {headline_1}\",\n","                            \"image_b_description\": f\"Description: {description_2}\",\n","                            \"image_b_context\": f\"Alt Text: {alt_2}, Heading: {headline_2}\"\n","                        }\n","                        template = Template(prompt2 + cot)\n","                        rendered_text = template.render(data)\n","                        desc_index, _ = find_most_similar(description_1, desc, desc_embeddings)\n","                        few_shot_examples = generate_few_shot_examples(select_category, few_shot_df.loc[desc_index, 'image number'], desc)\n","                        prompt = few_shot_examples + rendered_text\n","                        row.append([headline_1, alt_1, images[i], images[j], headline_2, alt_2, prompt, ''])\n","\n","            pd.DataFrame(row, columns=columns).to_csv(f'{dir_path}/{category}', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Dynamic Few-shot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["websites = [] # Add sample\n","\n","prepare_few_shot_prompts(websites=websites, prompt=base_prompt)\n","run_llama(websites=websites, label='few-shot')\n","resolve_descripancies(websites=websites, label='few-shot')\n","compute_similarity_matrices(websites=websites, label='few-shot')"]},{"cell_type":"markdown","metadata":{},"source":["## Error testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_error_dir = '../src/description to output/prompting/test_error'\n","\n","def generate_error_testing_prompts():\n","    prompts = {}\n","\n","    for website in os.listdir(test_error_dir):\n","        for category in os.listdir(f'{test_error_dir}/{website}'):\n","            df = pd.read_csv(f'{test_error_dir}/{website}/{category}/image_data.csv')\n","            description_1, headline_1, alt_1 = extract_info(df.iloc[0])\n","            description_2, headline_2, alt_2 = extract_info(df.iloc[1])\n","            data = {\n","                \"image_a_description\": f\"Description: {description_1}\",\n","                \"image_a_context\": f\"Alt Text: {alt_1}, Heading: {headline_1}\",\n","                \"image_b_description\": f\"Description: {description_2}\",\n","                \"image_b_context\": f\"Alt Text: {alt_2}, Heading: {headline_2}\"\n","            }\n","            template = Template(prompt1 + cot)\n","            prompt = template.render(data)\n","            prompts[df.loc[0, 'score']] = [prompt] * 20"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def run_tests(prompts):\n","    labels = {}\n","    token_ids = {}\n","\n","    pattern = r'<rating>\\s*[\\[\\s]*(\\d+)[\\]\\s]*</rating>'\n","\n","    for key, prompt_list in prompts.items():\n","        token_ids[key] = process_prompts(prompt_list)\n","\n","    sleep(60)\n","\n","    for key, ids in token_ids.items():\n","        responses = read_all_responses(ids)\n","        scores = []\n","        for resp in responses:\n","            match = re.search(pattern, resp)\n","            if match:\n","                scores.append(int(match.group(1)))\n","            else:\n","                scores.append(9)\n","        labels[key] = scores\n","    \n","    with open(f'{test_error_dir}/output.json', 'w') as f:\n","        f.write(dumps(labels))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMY19cgcRXqgthQdNvdgH2g","provenance":[{"file_id":"1sTGsL6LntatxfKogmkYC6FU3MIvstm-w","timestamp":1728592596344}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
