{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebPageTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "base_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webpagetest(url, api_key=API_KEY):\n",
    "    base_url = \"https://www.webpagetest.org/\"\n",
    "    endpoint = \"runtest.php\"\n",
    "    params = {\n",
    "        \"url\": url,\n",
    "        \"runs\": 1,\n",
    "        \"f\": \"json\",\n",
    "        \"browser\": \"Chrome\",  # Specify Chrome as the browser\n",
    "        \"location\": \"Dulles:Chrome\",  # Choose a Chrome-capable location\n",
    "        \"fvonly\" : 1\n",
    "        }\n",
    "\n",
    "    headers = {\n",
    "        \"X-WPT-API-KEY\": api_key  # Include the API key in the header\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.get(base_url + endpoint, params=params, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Extract and print relevant information\n",
    "        test_id = data[\"data\"][\"testId\"]\n",
    "        json_url = data[\"data\"][\"jsonUrl\"]\n",
    "        \n",
    "        return test_id, json_url\n",
    "    else:\n",
    "        print(f\"Error submitting test: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving article urls from websites in dataset (where applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = os.listdir(base_dir)\n",
    "data_frames = []\n",
    "\n",
    "for website in websites:\n",
    "    for category in os.listdir(f'{base_dir}/{website}'):\n",
    "        df = pd.read_csv(f'{base_dir}/{website}/{category}/image_data.csv')\n",
    "        if 'article_url' in df.columns:\n",
    "            df['website'] = [website] * df.shape[0]\n",
    "            df['category'] = [category] * df.shape[0]\n",
    "            df['page_weight_in_bytes'] = [''] * df.shape[0]\n",
    "            # bookkeeping of result urls for get requests\n",
    "            df['id'] = [''] * df.shape[0]\n",
    "            df['json_url'] = [''] * df.shape[0]\n",
    "            df = df.loc[:, ['website', 'category', 'article_number', 'article_url', 'page_weight_in_bytes', 'id', 'json_url']]\n",
    "            data_frames.append(df)\n",
    "\n",
    "combined_df = pd.concat(data_frames)\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "combined_df.to_csv('wpt_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Requests to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = combined_df.sample(1000)\n",
    "sample_websites = combined_df['website'].unique().tolist()\n",
    "\n",
    "for website in sample_websites:\n",
    "    website_df = combined_df.groupby('website').get_group(website)\n",
    "    urls = website_df['article_url'].tolist()\n",
    "    indices = website_df.index\n",
    "\n",
    "    # sequential requests due to API rate limits\n",
    "\n",
    "    id = []\n",
    "    json_url = []\n",
    "    for url in urls:\n",
    "        result = run_webpagetest(url)\n",
    "        if result is None:\n",
    "            id.append('None')\n",
    "            json_url.append('None')\n",
    "        else:\n",
    "            id.append(result[0])\n",
    "            json_url.append(result[1])\n",
    "    \n",
    "    combined_df.loc[indices, 'id'] = id\n",
    "    combined_df.loc[indices, 'json_url'] = json_url\n",
    "\n",
    "combined_df.to_csv('wpt_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Page Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_url(id):\n",
    "    return f'https://www.webpagetest.org/jsonResult.php?test={id}&highlight=1'\n",
    "\n",
    "def get_page_weight_in_bytes(id):\n",
    "    if id =='None':\n",
    "        return -1\n",
    "    url = create_result_url(id)\n",
    "    response = requests.get(url)\n",
    "    html_source = response.text\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    soup_str = str(soup)\n",
    "    temp = soup_str[soup_str.find('bytesIn'):]\n",
    "    return int(float(temp[:temp.find(',')].replace('bytesIn\": ', '')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralleiizing fetching responses with concurrent threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_responses(outputs, website):\n",
    "    response_outputs = [None] * len(outputs)  # Initialize to hold responses in the original order\n",
    "\n",
    "    # Filter only valid token IDs\n",
    "    valid_token_ids = [token_id for token_id in outputs if token_id is not None]\n",
    "\n",
    "    if valid_token_ids:  # Only proceed if we have valid token IDs\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            response_futures = {executor.submit(get_page_weight_in_bytes, token_id): idx for idx, token_id in enumerate(outputs) if token_id is not None}\n",
    "\n",
    "            for future in tqdm(concurrent.futures.as_completed(response_futures), total=len(response_futures), desc=f\"Fetching page weights: {website}\"):\n",
    "                idx = response_futures[future]  # Get the original index\n",
    "                response = future.result()\n",
    "                response_outputs[idx] = response  # Store the response at the original index\n",
    "\n",
    "    return response_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for website in websites:\n",
    "    website_df = combined_df.groupby('website').get_group(website)\n",
    "    indices = website_df.index\n",
    "    token_ids = website_df['id'].tolist()\n",
    "    responses = read_all_responses(token_ids, website)\n",
    "    combined_df.loc[indices, 'page_weight_in_bytes'] = responses\n",
    "\n",
    "combined_df.drop(['id', 'json_url', ], axis=1, inplace=True)\n",
    "combined_df.to_csv('wpt_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from the page_weights dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>category</th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_url</th>\n",
       "      <th>page_weight_in_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.nytimes.com/2024/10/04/arts/music/...</td>\n",
       "      <td>5835625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>edition.cnn.com</td>\n",
       "      <td>Politics Congress</td>\n",
       "      <td>12</td>\n",
       "      <td>https://edition.cnn.com/2023/10/23/politics/ho...</td>\n",
       "      <td>5322836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>auone.com</td>\n",
       "      <td>International</td>\n",
       "      <td>4</td>\n",
       "      <td>https://article.auone.jp/detail/1/4/8/407_8_r_...</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>edition.cnn.com</td>\n",
       "      <td>Politics Congress</td>\n",
       "      <td>9</td>\n",
       "      <td>https://edition.cnn.com/2023/10/24/politics/to...</td>\n",
       "      <td>4841045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>www.usatoday.com</td>\n",
       "      <td>Travel</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.usatoday.com/story/travel/cruises/...</td>\n",
       "      <td>6201197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              website           category  article_number   \n",
       "210   www.nytimes.com              Music               1  \\\n",
       "786   edition.cnn.com  Politics Congress              12   \n",
       "809         auone.com      International               4   \n",
       "784   edition.cnn.com  Politics Congress               9   \n",
       "456  www.usatoday.com             Travel               8   \n",
       "\n",
       "                                           article_url  page_weight_in_bytes  \n",
       "210  https://www.nytimes.com/2024/10/04/arts/music/...               5835625  \n",
       "786  https://edition.cnn.com/2023/10/23/politics/ho...               5322836  \n",
       "809  https://article.auone.jp/detail/1/4/8/407_8_r_...                  1974  \n",
       "784  https://edition.cnn.com/2023/10/24/politics/to...               4841045  \n",
       "456  https://www.usatoday.com/story/travel/cruises/...               6201197  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average page_weight in bytes: 4777977.88\n",
      "Average page_weight in MB: 4.5566347885131835\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average page_weight in bytes: {combined_df['page_weight_in_bytes'].mean()}\")\n",
    "print(f\"Average page_weight in MB: {combined_df['page_weight_in_bytes'].mean() / 1024**2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
